{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"lrProject\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"cruise_ship_info.csv\", inferSchema=True, \n",
    "                      header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = StringIndexer(inputCol=\"Cruise_line\", \n",
    "                   outputCol=\"Indexed_Cruise_line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_model = si.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_indexed_cruise_line = si_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+\n",
      "|Cruise_line|Indexed_Cruise_line|\n",
      "+-----------+-------------------+\n",
      "|    Azamara|               16.0|\n",
      "|    Azamara|               16.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "|   Carnival|                1.0|\n",
      "+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_with_indexed_cruise_line.select(\"Cruise_line\", \"Indexed_Cruise_line\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name',\n",
       " 'Cruise_line',\n",
       " 'Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density',\n",
       " 'crew',\n",
       " 'Indexed_Cruise_line']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_indexed_cruise_line.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: \n",
    "#### This is where we select features fairly at random. I have found that with age and tonnage, I obtained a slightly higher rmse and lower r2 value on the test dataset. Hence I removed these features from consideration. The correct way to select features, however, would be to use a held out test dataset and an additional validation data set. We would then choose the features that perform best on the validation data set and finally evaluate the model performance on the test dataset. This way we prevent overfitting to the test dataset. \n",
    "\n",
    "Note: The particular results obtained may also vary slightly with each run since the train test splitting is done by randomly selecting 70% data for training and 30% data for testing/evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Indexed_Cruise_line', \n",
    "#                                        'Age', \n",
    "#                                        'Tonnage', \n",
    "                                       'passengers',\n",
    "                                       'length', \n",
    "                                       'cabins', \n",
    "                                       'passenger_density'],\n",
    "                           outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(data_with_indexed_cruise_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      " |-- Indexed_Cruise_line: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This shows an additional features column that was the output column\n",
    "# for the VectorAssembler. \n",
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, Indexed_Cruise_line=16.0, features=DenseVector([16.0, 6.94, 5.94, 3.55, 42.64]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows that \"features\" column has the requiisite DenseVector \n",
    "# representation\n",
    "output.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output.select(\"features\", \"crew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|crew|\n",
      "+--------------------+----+\n",
      "|[16.0,6.94,5.94,3...|3.55|\n",
      "|[16.0,6.94,5.94,3...|3.55|\n",
      "|[1.0,14.86,7.22,7...| 6.7|\n",
      "|[1.0,29.74,9.53,1...|19.1|\n",
      "|[1.0,26.42,8.92,1...|10.0|\n",
      "|[1.0,20.52,8.55,1...| 9.2|\n",
      "|[1.0,20.52,8.55,1...| 9.2|\n",
      "|[1.0,20.56,8.55,1...| 9.2|\n",
      "|[1.0,20.52,8.55,1...| 9.2|\n",
      "|[1.0,37.0,9.51,14...|11.5|\n",
      "|[1.0,29.74,9.51,1...|11.6|\n",
      "|[1.0,14.52,7.27,7...| 6.6|\n",
      "|[1.0,20.52,8.55,1...| 9.2|\n",
      "|[1.0,20.52,8.55,1...| 9.2|\n",
      "|[1.0,21.24,9.63,1...| 9.3|\n",
      "|[1.0,29.74,9.51,1...|11.6|\n",
      "|[1.0,21.24,9.63,1...|10.3|\n",
      "|[1.0,20.52,8.55,1...| 9.2|\n",
      "|[1.0,21.24,9.63,1...| 9.3|\n",
      "|[1.0,20.52,8.55,1...| 9.2|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              crew|\n",
      "+-------+------------------+\n",
      "|  count|               110|\n",
      "|   mean| 7.945090909090913|\n",
      "| stddev|3.5355120427603914|\n",
      "|    min|               0.6|\n",
      "|    max|              21.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              crew|\n",
      "+-------+------------------+\n",
      "|  count|                48|\n",
      "|   mean| 7.448333333333333|\n",
      "| stddev|3.4405407376422517|\n",
      "|    min|              0.59|\n",
      "|    max|              13.6|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol=\"crew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = lr_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "| -0.7427130418986199|\n",
      "| -1.6483959229232834|\n",
      "| -1.0710804329679195|\n",
      "| -0.9810804329679197|\n",
      "|-0.22448552165879399|\n",
      "| 0.39677221572180876|\n",
      "|  0.8410991863472539|\n",
      "|-0.20104478953028249|\n",
      "| -1.0856830249242044|\n",
      "| -0.5122928589069335|\n",
      "|  0.5066047519067176|\n",
      "|  0.5066047519067176|\n",
      "|-0.15621285040799648|\n",
      "|  0.0939124698965923|\n",
      "|-0.00815665509676...|\n",
      "|  0.9876009509399672|\n",
      "|   1.140909152073883|\n",
      "| 0.14190709605654117|\n",
      "|  -1.260418835227048|\n",
      "| -0.7177465039877777|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.929765001249304"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925417599244097"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-spark-practice",
   "language": "python",
   "name": "python-spark-practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
